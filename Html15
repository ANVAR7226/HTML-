from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import csv
import time

def scrape_labirint():
    url = "https://www.labirint.ru/best/"
    
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")  
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    
    driver.get(url)
    time.sleep(3)
    
    books = driver.find_elements(By.CLASS_NAME, "product")[:10]  
    
    book_data = []
    
    for book in books:
        try:
            title = book.find_element(By.CLASS_NAME, "product-title").text.strip()
            author = book.find_element(By.CLASS_NAME, "product-author").text.strip()
            price = book.find_element(By.CLASS_NAME, "price-val").text.strip()
            rating = book.find_element(By.CLASS_NAME, "rating").get_attribute("class").count("star")
            
            if rating > 4.5:
                book_data.append([title, author, price, rating])
        except:
            continue
    
    driver.quit()
    
    with open("books.csv", "w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Название", "Автор", "Цена", "Рейтинг"])
        writer.writerows(book_data)
    
    print("Данные сохранены в books.csv")

if __name__ == "__main__":
    scrape_labirint()
